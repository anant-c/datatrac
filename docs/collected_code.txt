
=== datatrac/cli/commands/delete.py ===
# datatrac/cli/commands/delete.py
import typer
from typing_extensions import Annotated
from rich.console import Console
from datatrac.core.db import get_db
from datatrac.core.manager import DataManager

# In a real app, this would come from a secure config file or env variable
ADMIN_PASSWORD = "admin"

app = typer.Typer(help="Delete a dataset from the registry.")
console = Console()

@app.callback(invoke_without_command=True)
def delete(
    hash_to_delete: Annotated[str, typer.Argument(help="Full hash of the dataset to delete.")],
    password: Annotated[str, typer.Option(
        "--password",
        prompt=True,
        hide_input=True,
        help="Admin password is required to delete."
    )]
):
    """
    Permanently delete a dataset from the registry and filesystem.
    """
    if password != ADMIN_PASSWORD:
        console.print("[bold red]Error: Invalid admin password.[/bold red]")
        raise typer.Exit(code=1)

    try:
        db = next(get_db())
        manager = DataManager(db)
        success = manager.delete_dataset(hash_to_delete)
        if success:
            console.print(f"✅ Dataset [yellow]{hash_to_delete[:12]}...[/yellow] has been deleted.")
        else:
            console.print(f"[bold red]Error:[/bold red] Dataset with hash '{hash_to_delete}' not found.")
    except Exception as e:
        console.print(f"[bold red]An unexpected error occurred:[/bold red] {e}")

=== datatrac/cli/commands/fetch.py ===
# datatrac/cli/commands/fetch.py
from typing import Annotated, Optional
import typer
from rich.console import Console
from rich.table import Table
from datatrac.core.db import get_db
from datatrac.core.manager import DataManager

app = typer.Typer(help="Fetch dataset information from the registry.")
console = Console()

@app.callback(invoke_without_command=True)
def fetch(
    hash_prefix: Annotated[Optional[str], typer.Argument(help="The full hash of the dataset.")] = None,
    list_all: Annotated[bool, typer.Option("--all", "-a", help="List all datasets in the registry.")] = False,
    download: Annotated[bool, typer.Option("--download", help="Download the specified dataset.")] = False,
):
    """
    Fetch details, list all, or download datasets.
    """
    db = next(get_db())
    manager = DataManager(db)

    if download:
        if not hash_prefix:
            console.print("[bold red]Error:[/bold red] You must provide a dataset hash to download.")
            raise typer.Exit(code=1)
        try:
            downloaded_path = manager.download_dataset(hash_prefix)
            console.print(f"✅ Dataset downloaded successfully to: [green]{downloaded_path}[/green]")
        except (FileNotFoundError, RuntimeError) as e:
            console.print(f"[bold red]Error:[/bold red] {e}")
        return

    if list_all:
        datasets = manager.find_all()
        if not datasets:
            console.print("No datasets found in the registry.")
            return

        table = Table("Name", "Hash","Local Path" ,"Source", "Created At")
        for ds in datasets:
            table.add_row(ds.name, f"{ds.hash}", ds.local_path or "N/A", ds.source or "N/A", str(ds.created_at))
        console.print(table)
        
    elif hash_prefix:
        dataset = manager.find_by_hash(hash_prefix)
        if not dataset:
            console.print(f"[bold red]Error:[/bold red] Dataset with hash '{hash_prefix}' not found.")
            return
            
        console.print(f"[bold]Dataset Details for {dataset.name}[/bold]")
        console.print(f"  [cyan]Full Hash:[/cyan] {dataset.hash}")
        console.print(f"  [cyan]Source:[/cyan] {dataset.source or 'N/A'}")
        console.print(f"  [cyan]Original Path:[/cyan] {dataset.local_path}")
        console.print(f"  [cyan]Registry Path:[/cyan] {dataset.registry_path}")
        console.print(f"  [cyan]Created At:[/cyan] {dataset.created_at}")
    else:
        console.print("Please specify a dataset hash or use the --all or --download flag.")

=== datatrac/cli/commands/lineage.py ===
# datatrac/cli/commands/lineage.py
import typer
from typing import Optional
from typing_extensions import Annotated
from rich.console import Console
from rich.tree import Tree
from datatrac.core.db import get_db
from datatrac.core.manager import DataManager

app = typer.Typer(help="Create or view dataset lineage.")
console = Console()

@app.callback(invoke_without_command=True)
def lineage(
    hash_to_view: Annotated[Optional[str], typer.Argument(help="The hash of the dataset to view lineage for.")] = None,
    parent: Annotated[Optional[str], typer.Option("--parent", help="Hash of the parent dataset.")] = None,
    child: Annotated[Optional[str], typer.Option("--child", help="Hash of the child (derived) dataset.")] = None,
):
    """
    View lineage for a dataset OR create a new lineage link.

    - To VIEW: datatrac lineage <hash>
    - To CREATE: datatrac lineage --parent <hash1> --child <hash2>
    """
    db = next(get_db())
    manager = DataManager(db)

    # --- Mode 1: View Lineage ---
    if hash_to_view:
        try:
            dataset = manager.find_by_hash(hash_to_view)
            if not dataset:
                console.print(f"[red]Dataset with hash {hash_to_view} not found.[/red]")
                raise typer.Exit(1)
            
            lineage_data = manager.get_lineage(hash_to_view)

            tree = Tree(f"⛓️ [bold]Lineage for [cyan]{dataset.name}[/cyan] ([yellow]{dataset.hash[:12]}...[/yellow])")
            
            # Add parents
            if lineage_data["parents"]:
                parent_branch = tree.add("🔼 [bold green]Parents[/bold green] (Derived From)")
                for p in lineage_data["parents"]:
                    parent_branch.add(f"[cyan]{p['name']}[/cyan] ([yellow]{p['hash'][:12]}...[/yellow])")
            else:
                 tree.add("🔼 No parents found.")

            # Add children
            if lineage_data["children"]:
                child_branch = tree.add("🔽 [bold magenta]Children[/bold magenta] (Derived To)")
                for c in lineage_data["children"]:
                    child_branch.add(f"[cyan]{c['name']}[/cyan] ([yellow]{c['hash'][:12]}...[/yellow])")
            else:
                tree.add("🔽 No children found.")

            console.print(tree)

        except (FileNotFoundError, RuntimeError) as e:
            console.print(f"[bold red]Error:[/bold red] {e}")

    # --- Mode 2: Create Lineage ---
    elif parent and child:
        try:
            manager.create_lineage(parent_hash=parent, child_hash=child)
            console.print(
                "✅ Lineage created: "
                f"[yellow]{parent[:8]}...[/yellow] -> [green]{child[:8]}...[/green]"
            )
        except ValueError as e:
            console.print(f"[bold red]Error:[/bold red] {e}")
    
    # --- No valid options provided ---
    else:
        console.print("Usage error: Provide a hash to view, or --parent and --child to create a link.")
        raise typer.Exit(1)

=== datatrac/cli/commands/push.py ===
# datatrac/cli/commands/push.py
from typing import Annotated
import typer
from rich.console import Console
from datatrac.core.db import get_db
from datatrac.core.manager import DataManager

app = typer.Typer(help="Push a dataset to the registry.")
console = Console()

@app.callback(invoke_without_command=True)
def push(
    local_path: Annotated[str, typer.Argument(help="The local path to the dataset file.")],
    source: Annotated[str, typer.Option("--source", "-s", help="The original source URL of the dataset.")] = None
):
    """
    Hash a local dataset file and add it to the registry.
    """
    try:
        db_session = next(get_db())
        manager = DataManager(db_session)
        dataset = manager.push_dataset(local_path, source)
        console.print(f"✅ Dataset '[bold cyan]{dataset.name}[/bold cyan]' pushed successfully!")
        console.print(f"   Hash: [yellow]{dataset.hash}[/yellow]")
    except FileNotFoundError as e:
        console.print(f"[bold red]Error:[/bold red] {e}")
    except Exception as e:
        console.print(f"[bold red]An unexpected error occurred:[/bold red] {e}")

=== datatrac/cli/main.py ===
# datatrac/cli/main.py
import typer
from rich.console import Console
from datatrac.core.db import create_database_tables
from .commands import fetch, push, lineage, delete

# Initialize rich console for beautiful output
console = Console()

# Create the main Typer application
app = typer.Typer(
    name="datatrac",
    help="A tool to discover, manage, and trace data files efficiently.",
    add_completion=False,
)

# Add command groups (sub-commands)
app.add_typer(fetch.app, name="fetch")
app.add_typer(push.app, name="push")
app.add_typer(lineage.app, name="lineage")
app.add_typer(delete.app, name="delete")

@app.callback()
def main():
    """
    Manage your datasets with DataTrac.
    """
    # This is a good place to ensure the database and tables are created
    create_database_tables()

if __name__ == "__main__":
    app()

=== datatrac/core/config.py ===
# datatrac/core/config.py
import os
from pathlib import Path

# --- LOCAL CONFIGURATION ---
# Base directory for the application's local data (like the database)
APP_DIR = Path(os.getenv("DATATRAC_HOME", Path.home() / ".datatrac"))
# Path to the SQLite database
DATABASE_URL = f"sqlite:///{APP_DIR / 'datatrac.db'}"

# --- REMOTE REGISTRY CONFIGURATION ---
REMOTE_USER = "naruto"
REMOTE_HOST = "taklu.chickenkiller.com"
REMOTE_STORAGE_PATH = "/home/naruto/datasets"

# Helper to format the full SSH target address
REMOTE_TARGET = f"{REMOTE_USER}@{REMOTE_HOST}"

# Ensure the local app directory exists
APP_DIR.mkdir(exist_ok=True)

=== datatrac/core/db.py ===
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, declarative_base

from .config import DATABASE_URL

engine = create_engine(DATABASE_URL, connect_args={"check_same_thread": False})
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

def get_db():
    """Dependency to get a DB session."""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

def create_database_tables():
    """Creates all database tables."""
    # Import all models here before calling create_all
    # This ensures they are registered with Base.metadata
    from . import models
    Base.metadata.create_all(bind=engine)

=== datatrac/core/manager.py ===
# datatrac/core/manager.py
import shutil
import subprocess
from pathlib import Path
from sqlalchemy.orm import Session
from . import models, utils
from .config import REMOTE_TARGET, REMOTE_STORAGE_PATH

def run_command(command: list[str]):
    """Helper function to run a shell command and check for errors."""
    result = subprocess.run(command, capture_output=True, text=True)
    if result.returncode != 0:
        error_message = result.stderr or result.stdout
        raise RuntimeError(f"Command failed: {' '.join(command)}\nError: {error_message.strip()}")
    return result.stdout

class DataManager:
    def __init__(self, db: Session):
        self.db = db

    def find_by_hash(self, file_hash: str) -> models.Dataset | None:
        """Finds a dataset by its SHA256 hash."""
        return self.db.query(models.Dataset).filter(models.Dataset.hash == file_hash).first()

    def find_all(self):
        """Returns all datasets in the registry."""
        return self.db.query(models.Dataset).all()

    def push_dataset(self, local_path_str: str, source: str | None = None) -> models.Dataset:
        """Adds a dataset to the remote registry via SCP."""
        local_path = Path(local_path_str).resolve()
        if not local_path.exists():
            raise FileNotFoundError(f"File not found at: {local_path}")

        file_hash = utils.hash_file(str(local_path))
        
        existing_dataset = self.find_by_hash(file_hash)
        if existing_dataset:
            print(f"Dataset with hash {file_hash[:8]}... already exists.")
            return existing_dataset

        file_extension = local_path.suffix
        remote_filename = f"{file_hash}{file_extension}"
        remote_path_full = f"{REMOTE_STORAGE_PATH}/{remote_filename}"

        # Use SCP to copy the file to the remote server
        print(f"Uploading to {REMOTE_TARGET}...")
        scp_command = ["scp", str(local_path), f"{REMOTE_TARGET}:{remote_path_full}"]
        run_command(scp_command)
        print("Upload complete.")

        new_dataset = models.Dataset(
            hash=file_hash,
            name=local_path.name,
            source=source,
            local_path=str(local_path), # The original local path
            registry_path=remote_path_full, # The path on the remote server
        )
        self.db.add(new_dataset)
        self.db.commit()
        self.db.refresh(new_dataset)
        return new_dataset

    def download_dataset(self, file_hash: str, destination_dir: str = ".") -> Path:
        """Downloads a dataset from the remote registry to a local path."""
        dataset = self.find_by_hash(file_hash)
        if not dataset:
            raise FileNotFoundError(f"Dataset with hash {file_hash} not found in the database.")
        
        local_destination = Path(destination_dir).resolve() / dataset.name
        remote_source = f"{REMOTE_TARGET}:{dataset.registry_path}"

        print(f"Downloading from {REMOTE_TARGET} to {local_destination}...")
        scp_command = ["scp", remote_source, str(local_destination)]
        run_command(scp_command)
        print("Download complete.")
        return local_destination


    def create_lineage(self, parent_hash: str, child_hash: str) -> models.Lineage:
        """Creates a lineage link between two datasets."""
        parent = self.find_by_hash(parent_hash)
        if not parent:
            raise ValueError(f"Parent dataset with hash {parent_hash} not found.")
        
        child = self.find_by_hash(child_hash)
        if not child:
            raise ValueError(f"Child dataset with hash {child_hash} not found.")

        lineage_link = models.Lineage(parent_hash=parent_hash, child_hash=child_hash)
        self.db.add(lineage_link)
        self.db.commit()
        self.db.refresh(lineage_link)
        return lineage_link
    
    def get_lineage(self, file_hash: str) -> dict:
        """Retrieves all parents and children for a given dataset hash."""
        dataset = self.find_by_hash(file_hash)
        if not dataset:
            raise FileNotFoundError(f"Dataset with hash {file_hash} not found.")

        parents = [
            {"name": link.parent.name, "hash": link.parent.hash}
            for link in dataset.parents
        ]
        children = [
            {"name": link.child.name, "hash": link.child.hash}
            for link in dataset.children
        ]
        
        return {"parents": parents, "children": children}

    def delete_dataset(self, file_hash: str) -> bool:
        """Deletes a dataset from the remote registry and the database."""
        dataset = self.find_by_hash(file_hash)
        if not dataset:
            return False
        
        # Use SSH to remove the file on the remote server
        print(f"Deleting remote file: {dataset.registry_path}")
        ssh_command = ["ssh", REMOTE_TARGET, f"rm {dataset.registry_path}"]
        run_command(ssh_command)
        
        # Remove from database
        self.db.delete(dataset)
        self.db.commit()
        return True

=== datatrac/core/models.py ===
# datatrac/core/models.py
import datetime
from sqlalchemy import Column, String, DateTime, ForeignKey
from sqlalchemy.orm import relationship
from .db import Base

class Dataset(Base):
    __tablename__ = "datasets"

    hash = Column(String, primary_key=True, index=True)
    name = Column(String, index=True)
    source = Column(String, nullable=True)
    local_path = Column(String, unique=True)
    registry_path = Column(String, unique=True)
    created_at = Column(DateTime, default=datetime.datetime.utcnow)
    
    # Relationships for lineage
    parents = relationship(
        "Lineage",
        foreign_keys="[Lineage.child_hash]",
        back_populates="child",
        cascade="all, delete-orphan"
    )
    children = relationship(
        "Lineage",
        foreign_keys="[Lineage.parent_hash]",
        back_populates="parent",
        cascade="all, delete-orphan"
    )

class Lineage(Base):
    __tablename__ = "lineage"

    parent_hash = Column(String, ForeignKey("datasets.hash"), primary_key=True)
    child_hash = Column(String, ForeignKey("datasets.hash"), primary_key=True)
    
    parent = relationship("Dataset", foreign_keys=[parent_hash], back_populates="children")
    child = relationship("Dataset", foreign_keys=[child_hash], back_populates="parents")

=== datatrac/core/utils.py ===
# datatrac/core/utils.py
import hashlib

def hash_file(file_path: str) -> str:
    """Calculates the SHA256 hash of a file."""
    sha256_hash = hashlib.sha256()
    with open(file_path, "rb") as f:
        # Read and update hash in chunks to handle large files
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()
